# Success Metrics - 30-90 Day Tracking

Key metrics to track after v1.0.0 release.

## ğŸ¯ Target Metrics (30-90 days)

### Nightly Tests
- **Target**: Green rate â‰¥ 95%
- **Measurement**: `.github/workflows/hard-tests-nightly.yml` success rate
- **Tracking**: GitHub Actions workflow runs

### Performance
- **Target**: Runtime â†“ 20% in `hard_test.yaml` pipeline
- **Measurement**: Compare KPI baseline (`docs/benchmarks/baseline_latest.json`) vs current
- **Tracking**: Weekly KPI reports from nightly tests

### Code Coverage
- **Overall**: â‰¥ 85%
- **Core**: â‰¥ 95%
- **Orchestrator**: â‰¥ 90%
- **Agents/Advisors**: â‰¥ 80%
- **Measurement**: Codecov reports (component flags)
- **Tracking**: Weekly Codecov reports

### Plugin Ecosystem
- **Target**: At least 1 external "Hello-World" plugin passes CI
- **Measurement**: `.github/workflows/plugin-api-test.yml` with external plugin
- **Tracking**: GitHub Actions workflow runs

## ğŸ“Š Tracking Methods

### Automated Tracking

1. **GitHub Actions Metrics**
   - Nightly test success rate
   - Plugin API test runs
   - Coverage trends

2. **Codecov Dashboard**
   - Component coverage trends
   - Coverage by flag (agents, advisors, orchestrator, core)

3. **KPI Reports**
   - Weekly KPI aggregation
   - Performance trends
   - Baseline comparisons

### Manual Tracking

1. **Weekly Review**
   - Check GitHub Actions status
   - Review Codecov trends
   - Analyze KPI reports

2. **Monthly Report**
   - Aggregate metrics
   - Compare to targets
   - Identify regressions

## ğŸ“ˆ Baseline (v1.0.0)

### Current Baseline
- **Nightly Tests**: Baseline from first run
- **Performance**: Baseline from `docs/benchmarks/baseline_latest.json`
- **Coverage**: Initial coverage report
- **Plugins**: 0 external plugins

### Update Baseline
```bash
# Generate new baseline
python scripts/perf_baseline.py

# Compare baselines
diff docs/benchmarks/baseline_*.json
```

## ğŸ¯ Success Criteria

### 30 Days
- [ ] Nightly tests: â‰¥ 90% green
- [ ] Coverage: Overall â‰¥ 80%, Core â‰¥ 90%
- [ ] No critical regressions

### 60 Days
- [ ] Nightly tests: â‰¥ 95% green
- [ ] Performance: Runtime â†“ 10%
- [ ] Coverage: Overall â‰¥ 85%, Core â‰¥ 95%
- [ ] At least 1 external plugin in development

### 90 Days
- [ ] Nightly tests: â‰¥ 95% green
- [ ] Performance: Runtime â†“ 20%
- [ ] Coverage: All targets met
- [ ] At least 1 external plugin passes CI

## ğŸ“ Reporting

### Weekly Status
- Check GitHub Actions
- Review Codecov trends
- Analyze KPI reports

### Monthly Report Template
```markdown
# Monthly Metrics Report - [Month Year]

## Nightly Tests
- Success Rate: X%
- Target: â‰¥ 95%
- Status: âœ…/âŒ

## Performance
- Runtime Change: Â±X%
- Target: â†“ 20%
- Status: âœ…/âŒ

## Coverage
- Overall: X%
- Core: X%
- Target: Overall â‰¥ 85%, Core â‰¥ 95%
- Status: âœ…/âŒ

## Plugins
- External Plugins: X
- Target: â‰¥ 1 passing CI
- Status: âœ…/âŒ

## Notes
- [Any observations or issues]
```

## ğŸ” Monitoring

### GitHub Actions
- Monitor workflow runs
- Set up notifications for failures
- Track success rates

### Codecov
- Set up alerts for coverage drops
- Monitor component trends
- Review PR coverage reports

### KPIs
- Weekly KPI aggregation
- Compare to baseline
- Track trends over time

## See Also

- [Performance Baseline](docs/benchmarks/)
- [Codecov Dashboard](https://codecov.io/gh/<owner>/<repo>)
- [GitHub Actions](https://github.com/<owner>/<repo>/actions)
